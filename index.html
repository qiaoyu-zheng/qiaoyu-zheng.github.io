<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Qiaoyu Zheng [郑乔予]</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Georgia', 'Times New Roman', serif;
            line-height: 1.6;
            color: #2c3e50;
            background: #f8f9fa;
        }

        .header-section {
            background: linear-gradient(135deg, #e9ecef 0%, #dee2e6 100%);
            padding: 60px 20px;
            border-bottom: 1px solid #dee2e6;
        }

        .header-container {
            max-width: 1000px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            gap: 50px;
        }

        .profile-info {
            flex: 1;
        }

        .name {
            font-size: 2.5em;
            font-weight: bold;
            color: #2c3e50;
            margin-bottom: 20px;
        }

        .bio {
            font-size: 1.15em;
            margin-bottom: 18px;
            text-align: justify;
            color: #495057;
        }

        .contact-links {
            margin-top: 25px;
            display: flex;
            gap: 25px;
        }

        .contact-link {
            display: flex;
            align-items: center;
            gap: 8px;
            color: #3498db;
            text-decoration: none;
            font-weight: 500;
            font-size: 1.05em;
            transition: all 0.3s ease;
            padding: 8px 12px;
            border-radius: 6px;
        }

        .contact-link:hover {
            color: #2980b9;
            background: rgba(52, 152, 219, 0.1);
            transform: translateY(-2px);
        }

        .contact-link i {
            font-size: 1.2em;
        }

        .profile-image {
            width: 300px;
            height: 300px;
            border-radius: 50%;
            object-fit: cover;
            border: 6px solid #fff;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.15);
            transition: transform 0.3s ease;
        }

        .profile-image:hover {
            transform: scale(1.05);
        }

        .research-section {
            background: #fff;
            padding: 60px 20px;
        }

        .research-container {
            max-width: 1000px;
            margin: 0 auto;
        }

        .section-title {
            font-size: 2.2em;
            color: #2c3e50;
            margin-bottom: 50px;
            text-align: center;
            position: relative;
        }

        .section-title::after {
            content: '';
            position: absolute;
            bottom: -15px;
            left: 50%;
            transform: translateX(-50%);
            width: 80px;
            height: 4px;
            background: linear-gradient(90deg, #3498db, #2ecc71);
            border-radius: 2px;
        }

        .project {
            display: flex;
            gap: 40px;
            margin-bottom: 50px;
            padding: 30px;
            background: #fff;
            border-radius: 15px;
            box-shadow: 0 8px 25px rgba(0, 0, 0, 0.08);
            transition: all 0.3s ease;
            border: 1px solid #f1f3f4;
        }

        .project:hover {
            transform: translateY(-8px);
            box-shadow: 0 15px 40px rgba(0, 0, 0, 0.12);
        }

        .project-image {
            width: 320px;
            max-width: 320px;
            height: auto;
            object-fit: contain;
            border-radius: 10px;
            flex-shrink: 0;
            border: 1px solid #e9ecef;
        }

        .project-content {
            flex: 1;
            display: flex;
            flex-direction: column;
        }

        .project-title {
            font-size: 1.4em;
            font-weight: bold;
            color: #2c3e50;
            margin-bottom: 12px;
            text-decoration: none;
            transition: color 0.3s ease;
            line-height: 1.3;
        }

        .project-title:hover {
            color: #3498db;
        }

        .project-authors {
            font-size: 1em;
            color: #6c757d;
            margin-bottom: 10px;
            line-height: 1.4;
        }

        .project-venue {
            font-style: italic;
            color: #27ae60;
            margin-bottom: 15px;
            font-weight: 500;
        }

        .project-description {
            font-size: 1.05em;
            color: #495057;
            text-align: justify;
            line-height: 1.6;
            flex-grow: 1;
        }

        .highlight {
            font-weight: bold;
            color: #2c3e50;
        }

        .author-link {
            color: #3498db;
            text-decoration: none;
            transition: color 0.3s ease;
        }

        .author-link:hover {
            color: #2980b9;
            text-decoration: underline;
        }

        @media (max-width: 968px) {
            .header-container {
                flex-direction: column;
                text-align: center;
                gap: 30px;
            }

            .contact-links {
                justify-content: center;
                flex-wrap: wrap;
            }

            .project {
                flex-direction: column;
                gap: 25px;
            }

            .project-image {
                width: 100%;
                max-width: 100%;
                align-self: center;
            }

            .name {
                font-size: 2.2em;
            }

            .section-title {
                font-size: 1.9em;
            }

            .header-section {
                padding: 40px 20px;
            }

            .research-section {
                padding: 40px 20px;
            }
        }

        @media (max-width: 640px) {
            .contact-links {
                flex-direction: column;
                align-items: center;
                gap: 15px;
            }

            .contact-link {
                padding: 10px 15px;
            }

            .project {
                padding: 20px;
                margin-bottom: 30px;
            }

            .project-image {
                max-width: 280px;
            }
        }
    </style>
</head>

<body>
    <div class="header-section">
        <div class="header-container">
            <div class="profile-info">
                <div class="name">Qiaoyu Zheng (郑乔予)</div>
                <div class="bio">
                    Hello! I am a PhD student at <a href="https://mediabrain.sjtu.edu.cn/" class="author-link">Shanghai Jiao Tong University</a>, advised by <a href="https://weidixie.github.io/" class="author-link">Prof. Weidi Xie</a>. I graduated with a bachelor's degree in Computer Science from the School of Electronic Information and Electrical Engineering at Shanghai Jiao Tong University in June 2023.
                </div>
                <div class="bio">
                    My current research interest focuses on <strong>Artificial Intelligence for Healthcare (AI4Health)</strong>. I am looking forward to the day when AI in healthcare can truly benefit humanity.
                </div>
                <div class="contact-links">
                    <a href="mailto:three-world@sjtu.edu.cn" class="contact-link">
                        <i class="fas fa-envelope"></i>
                        Email
                    </a>
                    <a href="https://github.com/qiaoyu-zheng/" class="contact-link">
                        <i class="fab fa-github"></i>
                        Github
                    </a>
                    <a href="https://scholar.google.com/citations?user=JX0aJ2AAAAAJ&hl=zh-CN&oi=sra" class="contact-link">
                        <i class="fas fa-graduation-cap"></i>
                        Google Scholar
                    </a>
                </div>
            </div>
            <img src="image/Qiaoyu.png" alt="Qiaoyu Zheng" class="profile-image">
        </div>
    </div>

    <div class="research-section">
        <div class="research-container">
            <h2 class="section-title">Research</h2>

            <div class="project">
                <img src="image/Deep-DxSearch.png" alt="Deep-DxSearch" class="project-image">
                <div class="project-content">
                    <a href="https://qiaoyu-zheng.github.io/Deep-DxSearch" class="project-title">
                        End-to-End Agentic RAG System Training for Traceable Diagnostic Reasoning
                    </a>
                    <div class="project-authors">
                        <span class="highlight">Qiaoyu Zheng*</span>,
                        <a href="https://github.com/Sekiro-Sun" class="author-link">Yuze Sun*</a>,
                        <a href="https://chaoyi-wu.github.io/" class="author-link">Chaoyi Wu</a>,
                        <a href="https://angelakeke.github.io/" class="author-link">Weike Zhao</a>,
                        <a href="https://henrychur.github.io/" class="author-link">Pengcheng Qiu</a>,
                        <a href="https://www.shsmu.edu.cn/ekxy-en/info/1054/1402.htm" class="author-link">Yongguo Yu</a>,
                        Kun Sun,
                        <a href="https://mediabrain.sjtu.edu.cn/members/" class="author-link">Yanfeng Wang</a>,
                        <a href="https://mediabrain.sjtu.edu.cn/yazhang/" class="author-link">Ya Zhang†</a>,
                        <a href="https://weidixie.github.io/" class="author-link">Weidi Xie†</a>
                    </div>
                    <div class="project-venue">arXiv preprint, 2025</div>
                    <div class="project-description">
                        We introduce <strong>Deep-DxSearch</strong>, an end-to-end agentic RAG system trained with reinforcement learning for traceable diagnostic reasoning. Our framework addresses knowledge gaps and hallucinations in medical LLMs by constructing a large-scale medical retrieval corpus and using the LLM as a core agent with tailored rewards. Deep-DxSearch consistently outperforms prompt-engineering and training-free RAG approaches, achieving substantial gains over GPT-4o, DeepSeek-R1, and other medical frameworks for both common and rare disease diagnosis.
                    </div>
                </div>
            </div>

            <div class="project">
                <img src="image/M3Builder.png" alt="M3Builder" class="project-image">
                <div class="project-content">
                    <a href="https://arxiv.org/pdf/2502.20301" class="project-title">
                        M³Builder: A Multi-Agent System for Automated Machine Learning in Medical Imaging
                    </a>
                    <div class="project-authors">
                        Jinghao Feng*,
                        <span class="highlight">Qiaoyu Zheng*</span>,
                        <a href="https://chaoyi-wu.github.io/" class="author-link">Chaoyi Wu</a>,
                        Ziheng Zhao,
                        <a href="https://mediabrain.sjtu.edu.cn/yazhang/" class="author-link">Ya Zhang</a>,
                        <a href="https://mediabrain.sjtu.edu.cn/members/" class="author-link">Yanfeng Wang</a>,
                        <a href="https://weidixie.github.io/" class="author-link">Weidi Xie†</a>
                    </div>
                    <div class="project-venue">MICCAI Workshop, 2025, Oral</div>
                    <div class="project-description">
                        We present M³Builder, an LLM-powered multi-agent system for autonomous end-to-end medical imaging AI model training—the first to automate ML in medical imaging, lowering the threshold for clinicians to develop and apply AI models, and promoting the widespread adoption of AI tools in real clinical scenarios.
                    </div>
                </div>
            </div>

            <div class="project">
                <img src="image/RadABench.png" alt="RadABench" class="project-image">
                <div class="project-content">
                    <a href="https://arxiv.org/pdf/2412.09529" class="project-title">
                        How Well Can Modern LLMs Act as Agent Cores in Radiology Environments?
                    </a>
                    <div class="project-authors">
                        <span class="highlight">Qiaoyu Zheng*</span>,
                        <a href="https://chaoyi-wu.github.io/" class="author-link">Chaoyi Wu*</a>,
                        Pengcheng Qiu,
                        Lisong Dai,
                        <a href="https://mediabrain.sjtu.edu.cn/yazhang/" class="author-link">Ya Zhang</a>,
                        <a href="https://mediabrain.sjtu.edu.cn/members/" class="author-link">Yanfeng Wang†</a>,
                        <a href="https://weidixie.github.io/" class="author-link">Weidi Xie†</a>
                    </div>
                    <div class="project-venue">Technical Report, 2024</div>
                    <div class="project-description">
                        We evaluate modern LLMs as agent cores in radiology environments through a comprehensive dataset, innovative evaluation platform, and performance assessments of leading models. Results highlight key challenges in tool comprehension, information synthesis, and format maintenance, confirming that while promising, current LLMs are not yet ready to serve as standalone radiology agent cores.
                    </div>
                </div>
            </div>

            <div class="project">
                <img src="image/RP3D-Diag.png" alt="RP3D-Diag" class="project-image">
                <div class="project-content">
                    <a href="https://qiaoyu-zheng.github.io/RP3D-Diag" class="project-title">
                        Large-scale Long-tailed Disease Diagnosis on Radiology Images
                    </a>
                    <div class="project-authors">
                        <span class="highlight">Qiaoyu Zheng*</span>,
                        <a href="https://github.com/Angelakeke/" class="author-link">Weike Zhao*</a>,
                        <a href="https://chaoyi-wu.github.io/" class="author-link">Chaoyi Wu*</a>,
                        <a href="https://xiaoman-zhang.github.io/" class="author-link">Xiaoman Zhang</a>,
                        <a href="https://mediabrain.sjtu.edu.cn/yazhang/" class="author-link">Ya Zhang</a>,
                        <a href="https://mediabrain.sjtu.edu.cn/members/" class="author-link">Yanfeng Wang†</a>,
                        <a href="https://weidixie.github.io/" class="author-link">Weidi Xie†</a>
                    </div>
                    <div class="project-venue">Nature Communications, 2024</div>
                    <div class="project-description">
                        We build up an academically accessible, large-scale diagnostic dataset, present a knowledge enhanced model architecture that enables processing arbitrary number of input scans from various imaging modalities, and initialize a new benchmark for multi-modal multi-anatomy long-tailed diagnosis. Our method shows superior results and serves as a pre-trained model that can be finetuned to benefit diagnosis on various external datasets.
                    </div>
                </div>
            </div>

            <div class="project">
                <img src="image/GPT4V_eval.png" alt="GPT4V Evaluation" class="project-image">
                <div class="project-content">
                    <a href="https://drive.google.com/file/d/1kPDWgwpv8XlLu5sBuO2mRyylp0PDD6j5/view" class="project-title">
                        Can GPT-4V(ision) Serve Medical Applications? Case Studies on GPT-4V for Multimodal Medical Diagnosis
                    </a>
                    <div class="project-authors">
                        <a href="https://chaoyi-wu.github.io/" class="author-link">Chaoyi Wu*</a>,
                        Jiayu Lei*,
                        <span class="highlight">Qiaoyu Zheng*</span>,
                        Weike Zhao*,
                        Weixiong Lin*,
                        <a href="https://xiaoman-zhang.github.io/" class="author-link">Xiaoman Zhang*</a>,
                        Xiao Zhou*,
                        Ziheng Zhao*,
                        <a href="https://mediabrain.sjtu.edu.cn/yazhang/" class="author-link">Ya Zhang</a>,
                        <a href="https://mediabrain.sjtu.edu.cn/members/" class="author-link">Yanfeng Wang</a>,
                        <a href="https://weidixie.github.io/" class="author-link">Weidi Xie†</a>
                    </div>
                    <div class="project-venue">Technical Report, 2023</div>
                    <div class="project-description">
                        We present recent efforts on assessing GPT-4V for multimodal medical diagnosis through case studies, covering 17 human body systems across 8 clinical imaging modalities, including radiology and pathology.
                    </div>
                </div>
            </div>
        </div>
    </div>
</body>
</html>